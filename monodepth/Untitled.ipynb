{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in /home/tphan/.local/lib/python3.7/site-packages (3.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version == \"3.7\" in /home/tphan/.local/lib/python3.7/site-packages (from h5py) (1.19.4)\r\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /home/tphan/.local/lib/python3.7/site-packages (from h5py) (1.5.2)\r\n"
     ]
    }
   ],
   "source": [
    "!python3.7 -m pip install h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"rawDepths\": shape (2284, 640, 480), type \"<u2\">\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "f = h5py.File('nyu_depth_data_labeled.mat')\n",
    "images = f['images']\n",
    "labels = f['labels']\n",
    "depths = f['rawDepths']\n",
    "print(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_np_array(npa):\n",
    "    npa = npa.astype('int32')\n",
    "    normalized = (255*(npa - np.min(npa))/np.ptp(npa)).astype(int)\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 640, 480)\n",
      "(640, 480, 3)\n"
     ]
    }
   ],
   "source": [
    "images_to_test = images[:200]\n",
    "images_to_test\n",
    "print(images_to_test[0].shape)\n",
    "print(np.transpose(images_to_test[0], (1, 2, 0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#depths_to_test = depths[:200]\n",
    "#print(depths_to_test)\n",
    "#normalized_depths_to_test = normalize_np_array(depths_to_test)\n",
    "#print(normalized_depths_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from monodepth_model import *\n",
    "from monodepth_dataloader import *\n",
    "params = monodepth_parameters(\n",
    "        encoder='vgg',\n",
    "        height=256,\n",
    "        width=512,\n",
    "        batch_size=2,\n",
    "        num_threads=1,\n",
    "        num_epochs=1,\n",
    "        do_stereo=False,\n",
    "        wrap_mode=\"border\",\n",
    "        use_deconv=False,\n",
    "        alpha_image_loss=0,\n",
    "        disp_gradient_loss_weight=0,\n",
    "        lr_loss_weight=0,\n",
    "        full_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# We have prediction, which is 20 predictions of n x m images.\n",
    "# targets is the same dimensions.\n",
    "# To get the root mean squared error, we have to find \n",
    "def mean_squared_error(predictions, targets):\n",
    "    return ((predictions - targets) ** 2).mean()\n",
    "\n",
    "def post_process_disparity(disp):\n",
    "    _, h, w = disp.shape\n",
    "    l_disp = disp[0,:,:]\n",
    "    r_disp = np.fliplr(disp[1,:,:])\n",
    "    m_disp = 0.5 * (l_disp + r_disp)\n",
    "    l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "    l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
    "    r_mask = np.fliplr(l_mask)\n",
    "    return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp\n",
    "\n",
    "\n",
    "def test_simple_with_image_and_labels(params, input_image, labels, checkpoint_path, input_height, input_width, output_name='yikes'):\n",
    "    \"\"\"Test function.\"\"\"\n",
    "\n",
    "    left  = tf.placeholder(tf.float32, [2, input_height, input_width, 3])\n",
    "    model = MonodepthModel(params, \"test\", left, None)\n",
    "    input_image = np.transpose(input_image, (1, 2, 0))\n",
    "    original_height, original_width, num_channels = input_image.shape\n",
    "    input_image = scipy.misc.imresize(input_image, [input_height, input_width], interp='lanczos')\n",
    "    plt.imsave(\"raw{}.png\".format(output_name), input_image)\n",
    "    input_image = input_image.astype(np.float32) / 255\n",
    "    #input_image = np.transpose(input_image, (1, 2, 0))\n",
    "    print(input_image.shape)\n",
    "    input_images = np.stack((input_image, np.fliplr(input_image)), 0)\n",
    "\n",
    "    # SESSION\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    # SAVER\n",
    "    train_saver = tf.train.Saver()\n",
    "\n",
    "    # INIT\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    coordinator = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coordinator)\n",
    "\n",
    "    # RESTORE\n",
    "    restore_path = checkpoint_path.split(\".\")[0]\n",
    "    train_saver.restore(sess, restore_path)\n",
    "\n",
    "    disp = sess.run(model.disp_left_est[0], feed_dict={left: input_images})\n",
    "    disp_pp = post_process_disparity(disp.squeeze()).astype(np.float32)\n",
    "\n",
    "    disp_to_img = scipy.misc.imresize(disp_pp.squeeze(), [original_height, original_width])\n",
    "    resized = np.rot90(scipy.misc.imresize(disp_to_img, [640, 480]), 0)\n",
    "    plt.imsave(\"{}.png\".format(output_name), resized, cmap='gray')\n",
    "    # We have it, but resized to original size - let's check what it is\n",
    "    normalized_prediction = normalize_np_array(disp_to_img)\n",
    "    return mean_squared_error(normalized_prediction, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tphan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning:     `imresize` is deprecated!\n",
      "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "    Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 512, 3)\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "INFO:tensorflow:Restoring parameters from /home/tphan/monodepth/models/model_kitti/model_kitti\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tphan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:59: DeprecationWarning:     `imresize` is deprecated!\n",
      "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "    Use ``skimage.transform.resize`` instead.\n",
      "/home/tphan/.local/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning:     `imresize` is deprecated!\n",
      "    `imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "    Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9426.146214192708]\n",
      "(256, 512, 3)\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "INFO:tensorflow:Restoring parameters from /home/tphan/monodepth/models/model_kitti/model_kitti\n",
      "[9426.146214192708, 15757.810266927083]\n",
      "(256, 512, 3)\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "INFO:tensorflow:Restoring parameters from /home/tphan/monodepth/models/model_kitti/model_kitti\n",
      "[9426.146214192708, 15757.810266927083, 12116.045865885417]\n",
      "(256, 512, 3)\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "INFO:tensorflow:Restoring parameters from /home/tphan/monodepth/models/model_kitti/model_kitti\n",
      "[9426.146214192708, 15757.810266927083, 12116.045865885417, 20233.412747395832]\n",
      "(256, 512, 3)\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "INFO:tensorflow:Restoring parameters from /home/tphan/monodepth/models/model_kitti/model_kitti\n",
      "[9426.146214192708, 15757.810266927083, 12116.045865885417, 20233.412747395832, 16196.133011067708]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9426.146214192708,\n",
       " 15757.810266927083,\n",
       " 12116.045865885417,\n",
       " 20233.412747395832,\n",
       " 16196.133011067708]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mses = []\n",
    "iterations = 0\n",
    "max_iterations = 5\n",
    "for im, lb in zip(images, depths):\n",
    "    tf.reset_default_graph()\n",
    "    d = normalize_np_array(lb)\n",
    "    mses.append(test_simple_with_image_and_labels(params, im, d, '/home/tphan/monodepth/models/model_kitti/model_kitti', 256, 512, iterations))\n",
    "    print(mses)\n",
    "    iterations += 1\n",
    "    if iterations >= max_iterations:\n",
    "        break\n",
    "mses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_mses = sum(mses) / len(mses)\n",
    "import math\n",
    "print(math.sqrt(mean_of_mses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
